{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nkhairr/GPT-4.1/blob/main/mini_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini Project\n",
        "This notebook includes:\n",
        "- Integration of the GPT-4.1 model into a text-summarization pipeline  \n",
        "- A resume skill-extraction module powered by GPT-4.1\n",
        "\n"
      ],
      "metadata": {
        "id": "E_UQ0w2Lulle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Install dependencies:"
      ],
      "metadata": {
        "id": "GVJl9jOAMV7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet openai\n",
        "print(\"OpenAI client installed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9GqCtETutro",
        "outputId": "100ca76e-d449-400e-dae1-6ffb61e30b2d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI client installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Configure authentication:"
      ],
      "metadata": {
        "id": "RIfC_i8MM3Jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "from openai import OpenAI\n",
        "\n",
        "GITHUB_TOKEN = getpass(\"Paste your GitHub PAT (input is hidden): \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P93M91T1u3Ml",
        "outputId": "6cbd45cb-c705-4d8a-d742-185ebe262677"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your GitHub PAT (input is hidden): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    base_url=\"https://models.github.ai/inference/v1\",\n",
        "    api_key=GITHUB_TOKEN\n",
        ")\n",
        "print(\"Client created.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1gxeUNyvAWH",
        "outputId": "5e684fad-0a64-42fa-e7c6-14ec1c666d3a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Run the Text Summarizer (Simple Version)\n"
      ],
      "metadata": {
        "id": "Hn5zhxceNBwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_chat_call(prompt, model=\"gpt-4.1\", max_tokens=512, temperature=0.2):\n",
        "    \"\"\"\n",
        "    Simple wrapper for chat completions using the GitHub models endpoint.\n",
        "    Returns the model text (str).\n",
        "    \"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature\n",
        "    )\n",
        "\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "def summarize_to_3_bullets(text, model=\"gpt-4.1\"):\n",
        "    prompt = (\n",
        "        \"Summarize the following paragraph into exactly 3 concise bullet points. \"\n",
        "        \"Each bullet should be 1 short sentence (no numbering, each on its own line):\\n\\n\"\n",
        "        f\"---\\n{text}\\n---\\n\\nBullets:\"\n",
        "    )\n",
        "    return model_chat_call(prompt, model=model, max_tokens=200, temperature=0.1)\n",
        "\n",
        "\n",
        "example_paragraph = (\n",
        "    \"Open-source models and marketplaces let developers quickly try different \"\n",
        "    \"generative AI models without managing separate billing or API accounts. \"\n",
        "    \"GitHub's marketplace integrates models into repos and Actions, making it \"\n",
        "    \"easier to deploy AI-assisted workflows.\"\n",
        ")\n",
        "print(\"Summary:\\n\", summarize_to_3_bullets(example_paragraph))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mi--TOGvIIA",
        "outputId": "e66b53f8-1418-4419-8162-5151baf04b86"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " Open-source models and marketplaces enable fast experimentation with generative AI.  \n",
            "Developers avoid handling multiple billing and API accounts.  \n",
            "GitHub's marketplace streamlines AI workflow deployment in repos and Actions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 4) Run the Resume Skill Extractor (Simple Version)\n"
      ],
      "metadata": {
        "id": "lqIb_dHONYC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_skills_as_json(resume_paragraph, model=\"gpt-4.1\"):\n",
        "    prompt = (\n",
        "        \"Extract skills and technologies mentioned in the following resume paragraph. \"\n",
        "        \"Return a valid JSON array of skill strings only (e.g. [\\\"Python\\\", \\\"React\\\", \\\"TensorFlow\\\"]). \"\n",
        "        \"Do not include any extra text or explanation.\\n\\n\"\n",
        "        f\"Resume paragraph:\\n{resume_paragraph}\\n\\nJSON:\"\n",
        "    )\n",
        "    return model_chat_call(prompt, model=model, max_tokens=200, temperature=0.0)\n",
        "\n",
        "\n",
        "resume_txt = (\n",
        "    \"Experienced ML engineer with 3 years of experience in Python, PyTorch, and TensorFlow. \"\n",
        "    \"Also familiar with Docker, Kubernetes, and AWS (EC2, S3).\"\n",
        ")\n",
        "print(\"Extracted skills JSON:\\n\", extract_skills_as_json(resume_txt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpQKZOytveLZ",
        "outputId": "33ac5593-8ceb-444e-931a-ca0b6951b4ce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted skills JSON:\n",
            " [\"Python\", \"PyTorch\", \"TensorFlow\", \"Docker\", \"Kubernetes\", \"AWS\", \"EC2\", \"S3\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project Overview: My Accomplishments\n",
        "\n",
        " I successfully completed a mini-project in this notebook that demonstrated useful integrations of a large language model within two fundamental NLP workflows.  The key accomplishments include:\n",
        "\n",
        " 1. Model Integration & Environment Setup\n",
        "\n",
        " set up the environment and libraries needed to use GPT-4.1.\n",
        "\n",
        " Using appropriate API authentication, secure access to the model was established.\n",
        "\n",
        " Ensured a stable connection for inference operations within the notebook.\n",
        "\n",
        " 2. Text Summarisation Module\n",
        "\n",
        " Built a simple, functional text-summarization pipeline powered by GPT-4.1.\n",
        "\n",
        " Verified the model’s ability to condense long text into clear, high-quality summaries.\n",
        "\n",
        " showed how to modify the summariser to accommodate unique inputs.\n",
        "\n",
        "3. Skill Extraction Module for Resumes\n",
        "\n",
        " developed a model-driven, lightweight resume skill-extraction tool.\n",
        "\n",
        " Parsed raw text to identify key technical and soft skills.\n",
        "\n",
        " demonstrated how LLMs can automate useful HR-related tasks.\n",
        "\n",
        " 4. Complete Model Interaction\n",
        "\n",
        " Sent prompts to GPT-4.1 and validated structured, accurate responses.\n",
        "\n",
        " verified that the model environment is set up appropriately for complex natural language processing tasks.\n",
        "\n",
        " Demonstrated smooth integration and responsiveness across both modules."
      ],
      "metadata": {
        "id": "JzUayRwmPzL8"
      }
    }
  ]
}